# -*- coding: utf-8 -*-
"""Helen T - Model Toxicity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VfIW3p4kZk9TZNhmHCCMLuinzAKiPIBC

#Downloads

Installation for the following:


*   Pytorch Geometric (this might take like 44 minutes to download btw)
*   rdkit
*   selfies
*   datamol
"""

pip install rdkit

pip install selfies

pip install datamol

!pip install --verbose --no-cache-dir torch-scatter
!pip install --verbose --no-cache-dir torch-sparse
!pip install --verbose --no-cache-dir torch-cluster
!pip install torch-geometric
!pip install tensorboardX
!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip
!unzip ngrok-stable-linux-amd64.zip

"""#Preprocessing"""

from google.colab import drive
drive.mount('/content/drive')

# Load/import libraries
import numpy as np
import pandas as pd
import tensorflow as tf

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

from rdkit import Chem
from rdkit.Chem import PandasTools
import datamol as dm
import selfies as sf

dm.disable_rdkit_log()

"""Note: Tried to convert sdf to smiles to use as a df, decided it wouldn't be necessary for now so I'm just commenting everything to save it"""

# Converting the sdf file from SMILES to use as a df for Pandas

# Idk if this will work on your end because I copied the file path from my Google Drive
tox_df = '/content/drive/MyDrive/Helen Tran - Science Research 2024-2025/Data/tox21_10k_data_all.sdf'

tox_df = PandasTools.LoadSDF(tox_df, embedProps = True, molColName = None, smilesName = 'smiles')
print(tox_df)
tox_df[tox_df['FW'].notna()]

#gets constraints, which is cool
sf.get_semantic_constraints()

#NaN = unknown data/no data
#0/1 = no interaction
#remove all rows/columns with NaNs

# tox_df['NR-AR'] just gives the values in a specific column, 'NR-AR' is specific to this dataset
# notna excludes all NaNs
# pd.merge (df1, df2) merges the dfs together
# pd.merge(df1,df2, on=‘Formula’) keeps the Formula column constant, but all the other columns are merged

# Using datamol + RDKit for molecular standardization for preprocessing

#Doesn't work for now

smiles_column = "smiles"

def _preprocess(row):
    mol = dm.to_mol(row[smiles_column], ordered=True)
    mol = dm.fix_mol(mol)
    mol = dm.sanitize_mol(mol, sanifix=True, charge_neutral=False)
    mol = dm.standardize_mol(
        mol,
        disconnect_metals=False,
        normalize=True,
        reionize=True,
        uncharge=False,
        stereo=True,
    )

    try:
    # Code that may raise an exception
      x = [P-1] ; 6
      print(x)
    except:
    # exception occurs, if code under try throws error
      print("An exception occurred.")
    row["standard_smiles"] = dm.standardize_smiles(dm.to_smiles(mol))
    row["selfies"] = dm.to_selfies(mol)
    row["inchi"] = dm.to_inchi(mol)
    row["inchikey"] = dm.to_inchikey(mol)
    return row


data_clean = tox_df.apply(_preprocess, axis=1)
data_clean

#untested

smiles_column = "smiles"

def _preprocess(i, row):

    dm.disable_rdkit_log()

    mol = dm.to_mol(row[smiles_column], ordered=True)
    mol = dm.fix_mol(mol)
    mol = dm.sanitize_mol(mol, sanifix=True, charge_neutral=False)
    mol = dm.standardize_mol(
        mol, disconnect_metals=False, normalize=True, reionize=True, uncharge=False, stereo=True
    )

    row["standard_smiles"] = dm.standardize_smiles(dm.to_smiles(mol))
    row["selfies"] = dm.to_selfies(mol)
    row["inchi"] = dm.to_inchi(mol)
    row["inchikey"] = dm.to_inchikey(mol)
    return row


data_clean = dm.parallelized(_preprocess, tox_df.iterrows(), arg_type="args", progress=True, total=len(tox_df))
data_clean = pd.DataFrame(data_clean)
data_clean

"""#Graph Neural Network (Preprocessing isn't finished- It will need to be finished before we move onto this step!)"""

import torch
import torch.nn as nn
import torch.optim as optim

# fn = '/content/drive/MyDrive/Helen Tran - Science Research 2024-2025/Data/tox21_10k_data_all.sdf'

#convert numerical dataframe values to a torch tensor
tox_df = torch.tensor(tox_df)

#Feature selection

x_data = tensor(tox_df["Formula"])

y_data = tensor(tox_df["DSSTox_CID", "FW"])

# a very simple model with just one layer
class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.fc = nn.Linear(1, 1)  # 1 input, 1 output

    ## add more here if you'd like!

    def forward(self, x):

        ## add more here if you'd like! for now no need
        return self.fc(x)

# create model, define optimizer and loss function
model = SimpleModel()
optimizer = optim.Adam(model.parameters(), lr=0.01)
criterion = nn.MSELoss()

# Training loop (simplified)
for epoch in range(100):  # 100 epochs for training
    optimizer.zero_grad()  # Clear previous gradients

    # Forward pass
    output = model(x_data)  # Get the model's output

    # Compute loss
    loss = criterion(output, y_data)  # Compare output with true values

    # Backpropagation (compute gradients)
    loss.backward()

    # Update weights
    optimizer.step()

    # Print loss at each epoch
    print(f'Epoch {epoch+1}, Loss: {loss.item()}')